{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musiclm pytorch\n",
    "\n",
    "## Install depdency libraries first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install 'datasets[audio]' yt-dlp musiclm-pytorch tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "\n",
    "def download_clip(\n",
    "    video_identifier,\n",
    "    output_filename,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    tmp_dir='./tmp/musiccaps',\n",
    "    num_attempts=5,\n",
    "    url_base='https://www.youtube.com/watch?v='\n",
    "):\n",
    "    status = False\n",
    "\n",
    "    command = f\"\"\"\n",
    "        yt-dlp --quiet --no-warnings -x --audio-format wav -f bestaudio -o \"{output_filename}\" --download-sections \"*{start_time}-{end_time}\" {url_base}{video_identifier}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    attempts = 0\n",
    "    while True:\n",
    "        try:\n",
    "            output = subprocess.check_output(command, shell=True,\n",
    "                                                stderr=subprocess.STDOUT)\n",
    "        except subprocess.CalledProcessError as err:\n",
    "            attempts += 1\n",
    "            if attempts == num_attempts:\n",
    "                return status, err.output\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Check if the video was successfully saved.\n",
    "    status = os.path.exists(output_filename)\n",
    "    return status, 'Downloaded'\n",
    "\n",
    "def main(\n",
    "    data_dir: str,\n",
    "    sampling_rate: int = 44100,\n",
    "    limit: int = None,\n",
    "    num_proc: int = 1,\n",
    "    writer_batch_size: int = 1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Download the clips within the MusicCaps dataset from YouTube.\n",
    "    Args:\n",
    "        data_dir: Directory to save the clips to.\n",
    "        sampling_rate: Sampling rate of the audio clips.\n",
    "        limit: Limit the number of examples to download.\n",
    "        num_proc: Number of processes to use for downloading.\n",
    "        writer_batch_size: Batch size for writing the dataset. This is per process.\n",
    "    \"\"\"\n",
    "\n",
    "    ds = load_dataset('google/MusicCaps', split='train')\n",
    "    if limit is not None:\n",
    "        print(f\"Limiting to {limit} examples\")\n",
    "        ds = ds.select(range(limit))\n",
    "\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    def process(example):\n",
    "        outfile_path = str(data_dir / f\"{example['ytid']}.wav\")\n",
    "        status = True\n",
    "        if not os.path.exists(outfile_path):\n",
    "            status = False\n",
    "            print(f\"Working on {example['ytid']}..\")\n",
    "            status, log = download_clip(\n",
    "                example['ytid'],\n",
    "                outfile_path,\n",
    "                example['start_s'],\n",
    "                example['end_s'],\n",
    "            )\n",
    "            print(f\"Result: {status}\\nLOG: {log}\\n\\n\")\n",
    "\n",
    "        example['audio'] = outfile_path\n",
    "        example['download_status'] = status\n",
    "        return example\n",
    "\n",
    "    return ds.map(\n",
    "        process,\n",
    "        num_proc=num_proc,\n",
    "        writer_batch_size=writer_batch_size,\n",
    "        keep_in_memory=False\n",
    "    ).cast_column('audio', Audio(sampling_rate=sampling_rate))\n",
    "\n",
    "ds = main('./music_data', num_proc=2, limit=30, writer_batch_size=4) # change limit for larger dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from musiclm_pytorch import MuLaN, MuLaNTrainer, AudioSpectrogramTransformer, TextTransformer, MuLaNEmbedQuantizer, MusicLM\n",
    "from audiolm_pytorch import SoundStream, SoundStreamTrainer, HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer, HubertWithKmeans, CoarseTransformer, CoarseTransformerWrapper, CoarseTransformerTrainer, FineTransformer, FineTransformerWrapper, FineTransformerTrainer, AudioLM\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "audio_transformer = AudioSpectrogramTransformer(\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    dim_head = 64,\n",
    "    spec_n_fft = 128,\n",
    "    spec_win_length = 24,\n",
    "    spec_aug_stretch_factor = 0.8\n",
    ")\n",
    "\n",
    "text_transformer = TextTransformer(\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    dim_head = 64\n",
    ")\n",
    "\n",
    "class TextAudioDataset(Dataset):\n",
    "    def __init__(self, dset):\n",
    "        super().__init__()\n",
    "        self.dset = dset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ex = self.dset[idx]\n",
    "        caption = ex['caption']\n",
    "        wav, samplerate = torchaudio.load(ex['audio']['path'])\n",
    "        return caption, wav\n",
    "\n",
    "mulan = MuLaN(\n",
    "    audio_transformer = audio_transformer,\n",
    "    text_transformer = text_transformer\n",
    ")\n",
    "\n",
    "\n",
    "audio_transformer = AudioSpectrogramTransformer(\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    dim_head = 64,\n",
    "    spec_n_fft = 128,\n",
    "    spec_win_length = 24,\n",
    "    spec_aug_stretch_factor = 0.8\n",
    ")\n",
    "\n",
    "text_transformer = TextTransformer(\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    dim_head = 64\n",
    ")\n",
    "\n",
    "mulan = MuLaN(\n",
    "    audio_transformer = audio_transformer,\n",
    "    text_transformer = text_transformer\n",
    ")\n",
    "\n",
    "# trainer = MuLaNTrainer(\n",
    "#     mulan = mulan,\n",
    "#     dataset = TextAudioDataset(ds),\n",
    "#     batch_size = 3\n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "quantizer = MuLaNEmbedQuantizer(\n",
    "    mulan = mulan,                          # pass in trained mulan from above\n",
    "    conditioning_dims = (1024, 1024, 1024), # say all three transformers have model dimensions of 1024\n",
    "    namespaces = ('semantic', 'coarse', 'fine')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, file_name):\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        response = requests.get(url)\n",
    "        file.write(response.content)\n",
    "\n",
    "def get_hubert():\n",
    "    # Create a folder called hubert\n",
    "    os.mkdir(\"hubert\")\n",
    "\n",
    "    # Download the files\n",
    "    download_file(\"https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960.pt\", \"hubert/hubert_base_ls960.pt\")\n",
    "    download_file(\"https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960_L9_km500.bin\", \"hubert/hubert_base_ls960_L9_km500.bin\")\n",
    "\n",
    "get_hubert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav2vec = HubertWithKmeans(\n",
    "    checkpoint_path = './hubert/hubert_base_ls960.pt',\n",
    "    kmeans_path = './hubert/hubert_base_ls960_L9_km500.bin'\n",
    ")\n",
    "\n",
    "semantic_transformer = SemanticTransformer(\n",
    "    num_semantic_tokens = wav2vec.codebook_size,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    audio_text_condition = True      # this must be set to True (same for CoarseTransformer and FineTransformers)\n",
    ")#.cuda()\n",
    "\n",
    "# trainer = SemanticTransformerTrainer(\n",
    "#     transformer = semantic_transformer,\n",
    "#     wav2vec = wav2vec,\n",
    "#     audio_conditioner = quantizer,   # pass in the MulanEmbedQuantizer instance above\n",
    "#     folder ='./music_data',\n",
    "#     batch_size = 1,\n",
    "#     data_max_length = 320 * 32,\n",
    "#     num_train_steps = 1\n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "soundstream = SoundStream(\n",
    "    codebook_size = 1024,\n",
    "    rq_num_quantizers = 8,\n",
    ")\n",
    "\n",
    "# trainer = SoundStreamTrainer(\n",
    "#     soundstream,\n",
    "#     folder = './music_data',\n",
    "#     batch_size = 4,\n",
    "#     grad_accum_every = 8,         # effective batch size of 32\n",
    "#     data_max_length = 320 * 32,\n",
    "#     save_results_every = 2,\n",
    "#     save_model_every = 4,\n",
    "#     num_train_steps = 9\n",
    "# )#.cuda()\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "\n",
    "wav2vec = HubertWithKmeans(\n",
    "    checkpoint_path = './hubert/hubert_base_ls960.pt',\n",
    "    kmeans_path = './hubert/hubert_base_ls960_L9_km500.bin'\n",
    ")\n",
    "\n",
    "# soundstream = SoundStream(\n",
    "#     codebook_size = 1024,\n",
    "#     rq_num_quantizers = 8,\n",
    "# )\n",
    "\n",
    "# soundstream.load(\"./results/soundstream.8.pt\")\n",
    "\n",
    "coarse_transformer = CoarseTransformer(\n",
    "    num_semantic_tokens = wav2vec.codebook_size,\n",
    "    codebook_size = 1024,\n",
    "    num_coarse_quantizers = 3,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    audio_text_condition = True\n",
    ")\n",
    "\n",
    "# trainer = CoarseTransformerTrainer(\n",
    "#     transformer = coarse_transformer,\n",
    "#     soundstream = soundstream,\n",
    "#     audio_conditioner = quantizer,\n",
    "#     wav2vec = wav2vec,\n",
    "#     folder = './music_data',\n",
    "#     batch_size = 1,\n",
    "#     data_max_length = 320 * 32,\n",
    "#     save_results_every = 2,\n",
    "#     save_model_every = 4,\n",
    "#     num_train_steps = 9\n",
    "# )\n",
    "# NOTE: I changed num_train_steps to 9 (aka 8 + 1) from 10000 to make things go faster for demo purposes\n",
    "# adjusting save_*_every variables for the same reason\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "fine_transformer = FineTransformer(\n",
    "    num_coarse_quantizers = 3,\n",
    "    num_fine_quantizers = 5,\n",
    "    codebook_size = 1024,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    audio_text_condition = True\n",
    ")\n",
    "\n",
    "# trainer = FineTransformerTrainer(\n",
    "#     transformer = fine_transformer,\n",
    "#     soundstream = soundstream,\n",
    "#     audio_conditioner = quantizer,\n",
    "#     folder = './music_data',\n",
    "#     batch_size = 1,\n",
    "#     data_max_length = 320 * 32,\n",
    "#     num_train_steps = 9\n",
    "# )\n",
    "# NOTE: I changed num_train_steps to 9 (aka 8 + 1) from 10000 to make things go faster for demo purposes\n",
    "# adjusting save_*_every variables for the same reason\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "from musiclm_pytorch import MusicLM\n",
    "\n",
    "audiolm = AudioLM(\n",
    "    wav2vec = wav2vec,\n",
    "    soundstream = soundstream,\n",
    "    semantic_transformer = semantic_transformer,\n",
    "    coarse_transformer = coarse_transformer,\n",
    "    fine_transformer = fine_transformer\n",
    ")\n",
    "musiclm = MusicLM(\n",
    "    audio_lm = audiolm,\n",
    "    mulan_embed_quantizer = quantizer\n",
    ")\n",
    "\n",
    "title = 'the crystalline sounds of the piano in a ballroom'\n",
    "\n",
    "print(\"title:\", title)\n",
    "music = musiclm([title]) # torch.Tensor\n",
    "\n",
    "output_path = \"out.wav\"\n",
    "sample_rate = 44100\n",
    "torchaudio.save(output_path, music.cpu(), sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
